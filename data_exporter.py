#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¯¼å‡ºå·¥å…· - å°†æ‰€æœ‰æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´æ ¼å¼
ç”¨äºæŸ¥çœ‹å’Œå¯¼å‡ºæ•°æ®åº“ä¸­çš„æ•°æ®ï¼Œæ—¶é—´æˆ³è‡ªåŠ¨è½¬æ¢ä¸ºå¯è¯»çš„åŒ—äº¬æ—¶é—´
"""

import json
import csv
import pytz
from datetime import datetime
from typing import List, Dict, Any, Optional
from database_manager import D1DatabaseManager

class DataExporter:
    """æ•°æ®å¯¼å‡ºå™¨ - è‡ªåŠ¨è½¬æ¢æ—¶é—´æ ¼å¼"""
    
    def __init__(self):
        self.db = D1DatabaseManager()
        self.beijing_tz = pytz.timezone('Asia/Shanghai')
        self.utc_tz = pytz.UTC
    
    def convert_timestamp_to_beijing(self, timestamp: int) -> str:
        """å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²"""
        if not timestamp:
            return "æœªçŸ¥æ—¶é—´"
        
        try:
            # å°†UTCæ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
            utc_dt = datetime.fromtimestamp(timestamp, tz=self.utc_tz)
            beijing_dt = utc_dt.astimezone(self.beijing_tz)
            return beijing_dt.strftime('%Y-%m-%d %H:%M:%S CST')
        except (ValueError, TypeError, OSError):
            return "æ—¶é—´æ ¼å¼é”™è¯¯"
    
    def format_post_data(self, post: Dict) -> Dict:
        """æ ¼å¼åŒ–å•ä¸ªå¸–å­æ•°æ®ï¼Œè½¬æ¢æ—¶é—´æˆ³"""
        formatted_post = post.copy()
        
        # è½¬æ¢æ—¶é—´å­—æ®µ
        time_fields = ['created_utc', 'crawl_timestamp', 'processed_at', 'last_updated']
        
        for field in time_fields:
            if field in formatted_post and formatted_post[field]:
                # ä¿ç•™åŸå§‹æ—¶é—´æˆ³ï¼ˆæ·»åŠ _rawåç¼€ï¼‰
                formatted_post[f"{field}_raw"] = formatted_post[field]
                # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
                formatted_post[f"{field}_beijing"] = self.convert_timestamp_to_beijing(formatted_post[field])
                # æ›¿æ¢åŸå­—æ®µä¸ºå¯è¯»æ ¼å¼
                formatted_post[field] = formatted_post[f"{field}_beijing"]
        
        return formatted_post
    
    def export_posts_today(self, format_type: str = 'json') -> str:
        """å¯¼å‡ºä»Šæ—¥é‡‡é›†çš„å¸–å­æ•°æ®"""
        # è·å–ä»Šæ—¥æ•°æ®
        today = datetime.now(self.beijing_tz).strftime('%Y-%m-%d')
        
        sql = """
        SELECT * FROM reddit_ai_posts 
        WHERE crawl_date = ? 
        ORDER BY score DESC
        """
        
        result = self.db.execute_query(sql, [today])
        
        if not result.get('success', False):
            return f"æŸ¥è¯¢å¤±è´¥: {result}"
        
        posts = result.get('results', [])
        
        if not posts:
            return f"ä»Šæ—¥({today})æš‚æ— æ•°æ®"
        
        # æ ¼å¼åŒ–æ—¶é—´
        formatted_posts = [self.format_post_data(post) for post in posts]
        
        if format_type.lower() == 'csv':
            return self._export_to_csv(formatted_posts, f"reddit_ai_posts_{today}")
        else:
            return self._export_to_json(formatted_posts, f"reddit_ai_posts_{today}")
    
    def export_posts_by_date_range(self, start_date: str, end_date: str, format_type: str = 'json') -> str:
        """å¯¼å‡ºæŒ‡å®šæ—¥æœŸèŒƒå›´çš„å¸–å­æ•°æ®"""
        sql = """
        SELECT * FROM reddit_ai_posts 
        WHERE crawl_date BETWEEN ? AND ? 
        ORDER BY crawl_date DESC, score DESC
        """
        
        result = self.db.execute_query(sql, [start_date, end_date])
        
        if not result.get('success', False):
            return f"æŸ¥è¯¢å¤±è´¥: {result}"
        
        posts = result.get('results', [])
        
        if not posts:
            return f"æ—¥æœŸèŒƒå›´({start_date} åˆ° {end_date})æš‚æ— æ•°æ®"
        
        # æ ¼å¼åŒ–æ—¶é—´
        formatted_posts = [self.format_post_data(post) for post in posts]
        
        filename = f"reddit_ai_posts_{start_date}_to_{end_date}"
        
        if format_type.lower() == 'csv':
            return self._export_to_csv(formatted_posts, filename)
        else:
            return self._export_to_json(formatted_posts, filename)
    
    def export_top_posts(self, limit: int = 100, format_type: str = 'json') -> str:
        """å¯¼å‡ºè¯„åˆ†æœ€é«˜çš„å¸–å­"""
        sql = """
        SELECT * FROM reddit_ai_posts 
        ORDER BY score DESC 
        LIMIT ?
        """
        
        result = self.db.execute_query(sql, [limit])
        
        if not result.get('success', False):
            return f"æŸ¥è¯¢å¤±è´¥: {result}"
        
        posts = result.get('results', [])
        
        if not posts:
            return "æš‚æ— æ•°æ®"
        
        # æ ¼å¼åŒ–æ—¶é—´
        formatted_posts = [self.format_post_data(post) for post in posts]
        
        filename = f"reddit_ai_top_{limit}_posts"
        
        if format_type.lower() == 'csv':
            return self._export_to_csv(formatted_posts, filename)
        else:
            return self._export_to_json(formatted_posts, filename)
    
    def export_posts_by_subreddit(self, subreddit: str, format_type: str = 'json') -> str:
        """å¯¼å‡ºæŒ‡å®šç¤¾åŒºçš„å¸–å­æ•°æ®"""
        sql = """
        SELECT * FROM reddit_ai_posts 
        WHERE subreddit = ? 
        ORDER BY created_utc DESC
        """
        
        result = self.db.execute_query(sql, [subreddit])
        
        if not result.get('success', False):
            return f"æŸ¥è¯¢å¤±è´¥: {result}"
        
        posts = result.get('results', [])
        
        if not posts:
            return f"ç¤¾åŒº r/{subreddit} æš‚æ— æ•°æ®"
        
        # æ ¼å¼åŒ–æ—¶é—´
        formatted_posts = [self.format_post_data(post) for post in posts]
        
        filename = f"reddit_ai_{subreddit}_posts"
        
        if format_type.lower() == 'csv':
            return self._export_to_csv(formatted_posts, filename)
        else:
            return self._export_to_json(formatted_posts, filename)
    
    def _export_to_json(self, data: List[Dict], filename: str) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        filepath = f"/Users/momo/Desktop/reddit çˆ¬è™«/exports/{filename}.json"
        
        try:
            # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
            import os
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump({
                    "export_info": {
                        "total_records": len(data),
                        "export_time": datetime.now(self.beijing_tz).strftime('%Y-%m-%d %H:%M:%S CST'),
                        "timezone": "Asia/Shanghai (CST)",
                        "note": "æ‰€æœ‰æ—¶é—´æˆ³å·²è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"
                    },
                    "posts": data
                }, f, ensure_ascii=False, indent=2)
            
            return f"âœ… æˆåŠŸå¯¼å‡º {len(data)} æ¡è®°å½•åˆ°: {filepath}"
        
        except Exception as e:
            return f"âŒ å¯¼å‡ºå¤±è´¥: {e}"
    
    def _export_to_csv(self, data: List[Dict], filename: str) -> str:
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        if not data:
            return "æ²¡æœ‰æ•°æ®å¯å¯¼å‡º"
        
        filepath = f"/Users/momo/Desktop/reddit çˆ¬è™«/exports/{filename}.csv"
        
        try:
            # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
            import os
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # è·å–æ‰€æœ‰å­—æ®µå
            fieldnames = list(data[0].keys())
            
            with open(filepath, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
            
            return f"âœ… æˆåŠŸå¯¼å‡º {len(data)} æ¡è®°å½•åˆ°: {filepath}"
        
        except Exception as e:
            return f"âŒ å¯¼å‡ºå¤±è´¥: {e}"
    
    def view_posts_summary(self, limit: int = 10) -> str:
        """æŸ¥çœ‹å¸–å­æ‘˜è¦ï¼ˆæ§åˆ¶å°å‹å¥½æ ¼å¼ï¼‰"""
        sql = """
        SELECT id, title, subreddit, score, num_comments, 
               created_utc, crawl_date, ai_category
        FROM reddit_ai_posts 
        ORDER BY crawl_timestamp DESC 
        LIMIT ?
        """
        
        result = self.db.execute_query(sql, [limit])
        
        if not result.get('success', False):
            return f"æŸ¥è¯¢å¤±è´¥: {result}"
        
        posts = result.get('results', [])
        
        if not posts:
            return "æš‚æ— æ•°æ®"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = []
        output.append(f"\nğŸ“Š æœ€æ–° {len(posts)} æ¡å¸–å­æ‘˜è¦")
        output.append("=" * 80)
        
        for i, post in enumerate(posts, 1):
            # è½¬æ¢æ—¶é—´
            beijing_time = self.convert_timestamp_to_beijing(post.get('created_utc', 0))
            
            output.append(f"\n{i}. ã€r/{post.get('subreddit', 'Unknown')}ã€‘{post.get('title', 'æ— æ ‡é¢˜')[:60]}")
            output.append(f"   ğŸ“ˆ è¯„åˆ†: {post.get('score', 0)} | ğŸ’¬ è¯„è®º: {post.get('num_comments', 0)} | ğŸ·ï¸ åˆ†ç±»: {post.get('ai_category', 'æœªåˆ†ç±»')}")
            output.append(f"   ğŸ• å‘å¸ƒæ—¶é—´: {beijing_time} | ğŸ“… é‡‡é›†æ—¥æœŸ: {post.get('crawl_date', 'æœªçŸ¥')}")
            output.append(f"   ğŸ†” ID: {post.get('id', 'Unknown')}")
        
        output.append("\n" + "=" * 80)
        output.append(f"ğŸ’¡ æç¤º: ä½¿ç”¨ export_posts_today() å¯¼å‡ºå®Œæ•´æ•°æ®")
        
        return "\n".join(output)
    
    def get_statistics_with_beijing_time(self) -> str:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ—äº¬æ—¶é—´æ ¼å¼ï¼‰"""
        # æ€»å¸–å­æ•°
        total_result = self.db.execute_query("SELECT COUNT(*) as total FROM reddit_ai_posts")
        total_posts = total_result.get('results', [{}])[0].get('total', 0) if total_result.get('success') else 0
        
        # ä»Šæ—¥å¸–å­æ•°
        today = datetime.now(self.beijing_tz).strftime('%Y-%m-%d')
        today_result = self.db.execute_query("SELECT COUNT(*) as today_total FROM reddit_ai_posts WHERE crawl_date = ?", [today])
        today_posts = today_result.get('results', [{}])[0].get('today_total', 0) if today_result.get('success') else 0
        
        # æœ€æ–°å¸–å­æ—¶é—´
        latest_result = self.db.execute_query("SELECT MAX(created_utc) as latest_time FROM reddit_ai_posts")
        latest_timestamp = latest_result.get('results', [{}])[0].get('latest_time', 0) if latest_result.get('success') else 0
        latest_time = self.convert_timestamp_to_beijing(latest_timestamp)
        
        # æŒ‰ç¤¾åŒºç»Ÿè®¡
        subreddit_result = self.db.execute_query("""
            SELECT subreddit, COUNT(*) as count 
            FROM reddit_ai_posts 
            GROUP BY subreddit 
            ORDER BY count DESC 
            LIMIT 10
        """)
        subreddit_stats = subreddit_result.get('results', []) if subreddit_result.get('success') else []
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡
        date_result = self.db.execute_query("""
            SELECT crawl_date, COUNT(*) as daily_count 
            FROM reddit_ai_posts 
            GROUP BY crawl_date 
            ORDER BY crawl_date DESC 
            LIMIT 7
        """)
        date_stats = date_result.get('results', []) if date_result.get('success') else []
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = []
        output.append(f"\nğŸ“Š Reddit AIæ•°æ®åº“ç»Ÿè®¡æŠ¥å‘Š")
        output.append(f"ğŸ• ç”Ÿæˆæ—¶é—´: {datetime.now(self.beijing_tz).strftime('%Y-%m-%d %H:%M:%S CST')}")
        output.append("=" * 60)
        
        output.append(f"\nğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
        output.append(f"   æ€»å¸–å­æ•°: {total_posts:,} æ¡")
        output.append(f"   ä»Šæ—¥é‡‡é›†: {today_posts} æ¡ ({today})")
        output.append(f"   æœ€æ–°å¸–å­: {latest_time}")
        
        if subreddit_stats:
            output.append(f"\nğŸ¯ ç¤¾åŒºåˆ†å¸ƒ (Top 10):")
            for stat in subreddit_stats:
                output.append(f"   r/{stat.get('subreddit', 'Unknown')}: {stat.get('count', 0)} æ¡")
        
        if date_stats:
            output.append(f"\nğŸ“… æ¯æ—¥é‡‡é›†ç»Ÿè®¡ (æœ€è¿‘7å¤©):")
            for stat in date_stats:
                output.append(f"   {stat.get('crawl_date', 'Unknown')}: {stat.get('daily_count', 0)} æ¡")
        
        output.append("\n" + "=" * 60)
        
        return "\n".join(output)

def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼æ•°æ®æŸ¥çœ‹å’Œå¯¼å‡º"""
    exporter = DataExporter()
    
    print("ğŸš€ Reddit AI æ•°æ®å¯¼å‡ºå·¥å…·")
    print("ğŸ“… æ‰€æœ‰æ—¶é—´æˆ³è‡ªåŠ¨è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´æ ¼å¼")
    print("=" * 50)
    
    while True:
        print("\nå¯ç”¨æ“ä½œ:")
        print("1. æŸ¥çœ‹æœ€æ–°å¸–å­æ‘˜è¦")
        print("2. å¯¼å‡ºä»Šæ—¥æ•°æ® (JSON)")
        print("3. å¯¼å‡ºä»Šæ—¥æ•°æ® (CSV)")
        print("4. å¯¼å‡ºæŒ‡å®šæ—¥æœŸèŒƒå›´æ•°æ®")
        print("5. å¯¼å‡ºè¯„åˆ†æœ€é«˜å¸–å­")
        print("6. å¯¼å‡ºæŒ‡å®šç¤¾åŒºæ•°æ®")
        print("7. æŸ¥çœ‹æ•°æ®åº“ç»Ÿè®¡")
        print("8. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-8): ").strip()
        
        try:
            if choice == '1':
                limit = input("æ˜¾ç¤ºæ¡æ•° (é»˜è®¤10): ").strip() or "10"
                result = exporter.view_posts_summary(int(limit))
                print(result)
                
            elif choice == '2':
                result = exporter.export_posts_today('json')
                print(result)
                
            elif choice == '3':
                result = exporter.export_posts_today('csv')
                print(result)
                
            elif choice == '4':
                start_date = input("å¼€å§‹æ—¥æœŸ (YYYY-MM-DD): ").strip()
                end_date = input("ç»“æŸæ—¥æœŸ (YYYY-MM-DD): ").strip()
                format_type = input("æ ¼å¼ (json/csv, é»˜è®¤json): ").strip() or "json"
                result = exporter.export_posts_by_date_range(start_date, end_date, format_type)
                print(result)
                
            elif choice == '5':
                limit = input("å¯¼å‡ºæ¡æ•° (é»˜è®¤100): ").strip() or "100"
                format_type = input("æ ¼å¼ (json/csv, é»˜è®¤json): ").strip() or "json"
                result = exporter.export_top_posts(int(limit), format_type)
                print(result)
                
            elif choice == '6':
                subreddit = input("ç¤¾åŒºåç§° (å¦‚: ChatGPT): ").strip()
                format_type = input("æ ¼å¼ (json/csv, é»˜è®¤json): ").strip() or "json"
                result = exporter.export_posts_by_subreddit(subreddit, format_type)
                print(result)
                
            elif choice == '7':
                result = exporter.get_statistics_with_beijing_time()
                print(result)
                
            elif choice == '8':
                print("ğŸ‘‹ å†è§ï¼")
                break
                
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
                
        except ValueError as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
        except Exception as e:
            print(f"âŒ æ“ä½œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()

name: Daily Reddit AI Collect v3.0

on:
  schedule:
    - cron: '0 2 * * *'  # 每天UTC 2:00 (北京时间10:00)
  workflow_dispatch:
    inputs:
      target_count:
        description: '采集目标数量'
        required: false
        default: '1000'
        type: string

jobs:
  incremental-crawl:
    runs-on: ubuntu-latest
    name: Reddit AI数据增量采集
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run incremental crawl
        run: |
          echo "🚀 开始增量采集 - 只过滤当日已采集数据..."
          node scripts/incremental-crawl.js
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: 'reddit-ai-collect_v3/3.0.0 (by /u/ai_researcher)'
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          DATABASE_ID: ${{ secrets.DATABASE_ID }}

      - name: Database Statistics
        if: success()
        run: |
          echo "📊 获取数据库统计..."
          node -e "
          const CLOUDFLARE_API_TOKEN = process.env.CLOUDFLARE_API_TOKEN;
          const ACCOUNT_ID = process.env.ACCOUNT_ID;
          const DATABASE_ID = process.env.DATABASE_ID;
          
          async function getStats() {
            try {
              const response = await fetch(\`https://api.cloudflare.com/client/v4/accounts/\${ACCOUNT_ID}/d1/database/\${DATABASE_ID}/query\`, {
                method: 'POST',
                headers: {
                  'Authorization': \`Bearer \${CLOUDFLARE_API_TOKEN}\`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({ 
                  sql: 'SELECT collection_date, COUNT(*) as count FROM redditV2_posts GROUP BY collection_date ORDER BY collection_date DESC LIMIT 3;' 
                })
              });
              
              if (!response.ok) {
                throw new Error(\`HTTP \${response.status}\`);
              }
              
              const result = await response.json();
              const stats = result.result[0]?.results || [];
              
              console.log('📊 最近3日数据统计:');
              stats.forEach(row => {
                console.log(\`📅 \${row.collection_date}: \${row.count} 条帖子\`);
              });
              
              const todayCount = stats.find(s => s.collection_date === new Date().toISOString().split('T')[0])?.count || 0;
              console.log(\`::notice title=今日采集完成::新增 \${todayCount} 条帖子\`);
              
            } catch (error) {
              console.error('❌ 统计查询失败:', error.message);
            }
          }
          
          getStats();
          "
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          DATABASE_ID: ${{ secrets.DATABASE_ID }}

      - name: Upload logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: crawl-logs-${{ github.run_number }}
          path: data/
          retention-days: 3
